{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 数据预处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要用到paddlenlp这个包\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:25:54.108465Z",
     "iopub.status.busy": "2022-10-28T13:25:54.107916Z",
     "iopub.status.idle": "2022-10-28T13:25:55.586247Z",
     "shell.execute_reply": "2022-10-28T13:25:55.585462Z",
     "shell.execute_reply.started": "2022-10-28T13:25:54.108436Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddlenlp as ppnlp\n",
    "from paddlenlp.metrics import ChunkEvaluator\n",
    "from functools import partial\n",
    "from paddlenlp.data import Stack, Pad, Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 加载自定义数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:25:55.588182Z",
     "iopub.status.busy": "2022-10-28T13:25:55.587660Z",
     "iopub.status.idle": "2022-10-28T13:26:01.097025Z",
     "shell.execute_reply": "2022-10-28T13:26:01.096071Z",
     "shell.execute_reply.started": "2022-10-28T13:25:55.588156Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paddlenlp.datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "def read(data_path,is_test = False):\n",
    "    if not is_test:\n",
    "        data = pd.read_csv(data_path,encoding=\"gb18030\")\n",
    "        data.drop(index=18282,inplace=True)\n",
    "        for index,row in data.iterrows():\n",
    "            sentence = row[1]\n",
    "            labels = row[2]\n",
    "            yield {'text': sentence, 'label': labels}\n",
    "    else:\n",
    "        data = pd.read_csv(data_path,skiprows=40000,nrows=10000,encoding=\"gb18030\")\n",
    "        for index,row in data.iterrows():\n",
    "            sentence = row[1]\n",
    "            yield {'text': sentence}\n",
    "\n",
    "train_ds = load_dataset(read, data_path=\"./work/BDCI/train.csv\",is_test = False,lazy=False)\n",
    "test_ds = load_dataset(read, data_path=\"./work/BDCI/train.csv\",is_test = True,lazy=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 定义数据转换函数，实现文字编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:01.098824Z",
     "iopub.status.busy": "2022-10-28T13:26:01.098334Z",
     "iopub.status.idle": "2022-10-28T13:26:01.103671Z",
     "shell.execute_reply": "2022-10-28T13:26:01.103137Z",
     "shell.execute_reply.started": "2022-10-28T13:26:01.098793Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_example(example, tokenizer, max_seq_length=256,is_test=False):\n",
    "    encoded_inputs = tokenizer(example[\"text\"], max_seq_len=max_seq_length)\n",
    "    input_ids = encoded_inputs[\"input_ids\"]\n",
    "    token_type_ids = encoded_inputs[\"token_type_ids\"]\n",
    "    if not is_test:\n",
    "        label = [example[\"label\"]]\n",
    "        return input_ids, token_type_ids, label\n",
    "    else:\n",
    "        return input_ids, token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 构造偏函数，将单条数据进行转换\n",
    "此处需先定义tokenizer，再定义偏函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:01.105629Z",
     "iopub.status.busy": "2022-10-28T13:26:01.105196Z",
     "iopub.status.idle": "2022-10-28T13:26:01.238871Z",
     "shell.execute_reply": "2022-10-28T13:26:01.238299Z",
     "shell.execute_reply.started": "2022-10-28T13:26:01.105606Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-28 21:26:01,106] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie/vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-1.0\n",
      "[2022-10-28 21:26:01,109] [    INFO] - Downloading vocab.txt from https://paddlenlp.bj.bcebos.com/models/transformers/ernie/vocab.txt\n",
      "100%|██████████| 90/90 [00:00<00:00, 1898.86it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "max_seq_length = 312\n",
    "tokenizer = ppnlp.transformers.ErnieTokenizer.from_pretrained('ernie-1.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:01.240157Z",
     "iopub.status.busy": "2022-10-28T13:26:01.239660Z",
     "iopub.status.idle": "2022-10-28T13:26:01.253516Z",
     "shell.execute_reply": "2022-10-28T13:26:01.252989Z",
     "shell.execute_reply.started": "2022-10-28T13:26:01.240135Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 1073, 1169, 68, 2201, 4, 654, 4, 2670, 17, 5010, 136, 5010, 139, 39, 21, 4, 2746, 495, 4, 644, 219, 244, 484, 904, 308, 8, 4, 590, 12, 68, 73, 4, 87, 11, 644, 219, 244, 3376, 181, 488, 1769, 231, 1342, 4, 22, 171, 612, 8, 68, 2201, 1169, 1860, 2785, 1073, 4, 1079, 239, 9, 195, 1510, 1342, 681, 17, 627, 27, 136, 4, 145, 239, 1485, 192, 8, 119, 1387, 4225, 183, 12043, 803, 1079, 49, 4, 171, 612, 8, 16, 231, 4, 160, 39, 28, 1005, 12043, 1751, 181, 99, 663, 1631, 121, 8, 119, 594, 788, 245, 160, 39, 730, 1005, 12043, 644, 219, 244, 1751, 181, 99, 12, 222, 8, 119, 72, 245, 37, 1541, 17, 5010, 136, 5010, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [12])\n",
      "([1, 1073, 1169, 6196, 212, 900, 4, 557, 29, 132, 253, 81, 403, 6, 1224, 2633, 4, 654, 4, 2647, 17, 5010, 136, 5010, 139, 39, 21, 4, 657, 495, 4, 677, 219, 244, 8163, 2045, 308, 8, 4, 96, 18, 68, 73, 4, 250, 520, 677, 219, 244, 8163, 2045, 308, 550, 2158, 484, 192, 961, 148, 192, 604, 186, 4254, 500, 4, 87, 11, 296, 213, 1330, 495, 67, 301, 121, 12, 1631, 488, 1769, 231, 1342, 4, 22, 171, 612, 8, 6196, 212, 900, 1169, 470, 221, 767, 755, 1073, 4, 1079, 239, 154, 195, 1510, 1342, 4, 2477, 1486, 126, 301, 438, 217, 616, 262, 12043, 171, 612, 8, 6196, 212, 900, 16, 231, 4, 160, 39, 28, 1005, 12043, 296, 242, 244, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(convert_example(train_ds[100],tokenizer=tokenizer,max_seq_length=128,is_test=False))\n",
    "print(convert_example(test_ds[100],tokenizer=tokenizer,max_seq_length=128,is_test=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 构造batchify_fn，在batch数据构造时进行padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:01.254732Z",
     "iopub.status.busy": "2022-10-28T13:26:01.254270Z",
     "iopub.status.idle": "2022-10-28T13:26:01.258703Z",
     "shell.execute_reply": "2022-10-28T13:26:01.258129Z",
     "shell.execute_reply.started": "2022-10-28T13:26:01.254711Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batchify_fn_train = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "    Stack(dtype=\"int64\")  # label\n",
    "): [data for data in fn(samples)]\n",
    "batchify_fn_test = lambda samples, fn=Tuple(\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_id),  # input\n",
    "    Pad(axis=0, pad_val=tokenizer.pad_token_type_id),  # segment\n",
    "): [data for data in fn(samples)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 构造dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:01.259777Z",
     "iopub.status.busy": "2022-10-28T13:26:01.259424Z",
     "iopub.status.idle": "2022-10-28T13:26:01.262617Z",
     "shell.execute_reply": "2022-10-28T13:26:01.262105Z",
     "shell.execute_reply.started": "2022-10-28T13:26:01.259756Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trans_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer = tokenizer,    \n",
    "    max_seq_length = max_seq_length,\n",
    "    is_test = False)\n",
    "\n",
    "train_ds = train_ds.map(trans_func)\n",
    "# test_ds = test_ds.map(trans_func)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:01.263768Z",
     "iopub.status.busy": "2022-10-28T13:26:01.263336Z",
     "iopub.status.idle": "2022-10-28T13:26:01.267179Z",
     "shell.execute_reply": "2022-10-28T13:26:01.266669Z",
     "shell.execute_reply.started": "2022-10-28T13:26:01.263748Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = paddle.io.DataLoader(\n",
    "        dataset=train_ds,\n",
    "        batch_size=64,\n",
    "        collate_fn=batchify_fn_train,\n",
    "        shuffle=True,\n",
    "        return_list=True)\n",
    "     \n",
    "test_loader = paddle.io.DataLoader(\n",
    "        dataset=test_ds,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        collate_fn=batchify_fn_test,\n",
    "        return_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.定义分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:01.268226Z",
     "iopub.status.busy": "2022-10-28T13:26:01.267877Z",
     "iopub.status.idle": "2022-10-28T13:26:39.661468Z",
     "shell.execute_reply": "2022-10-28T13:26:39.660664Z",
     "shell.execute_reply.started": "2022-10-28T13:26:01.268206Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-28 21:26:01,269] [    INFO] - Downloading https://paddlenlp.bj.bcebos.com/models/transformers/ernie/ernie_v1_chn_base.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-1.0\n",
      "[2022-10-28 21:26:01,271] [    INFO] - Downloading ernie_v1_chn_base.pdparams from https://paddlenlp.bj.bcebos.com/models/transformers/ernie/ernie_v1_chn_base.pdparams\n",
      "100%|██████████| 392507/392507 [00:33<00:00, 11759.36it/s]\n",
      "W1028 21:26:34.730208   162 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1028 21:26:34.735143   162 device_context.cc:465] device: 0, cuDNN Version: 8.2.\n"
     ]
    }
   ],
   "source": [
    "model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained('ernie-1.0', num_classes=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:39.664768Z",
     "iopub.status.busy": "2022-10-28T13:26:39.664337Z",
     "iopub.status.idle": "2022-10-28T13:26:39.669544Z",
     "shell.execute_reply": "2022-10-28T13:26:39.669040Z",
     "shell.execute_reply.started": "2022-10-28T13:26:39.664741Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = paddle.optimizer.AdamW(learning_rate=2e-5, parameters=model.parameters())\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "metric = paddle.metric.Accuracy()\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:39.670714Z",
     "iopub.status.busy": "2022-10-28T13:26:39.670247Z",
     "iopub.status.idle": "2022-10-28T13:26:39.675888Z",
     "shell.execute_reply": "2022-10-28T13:26:39.675403Z",
     "shell.execute_reply.started": "2022-10-28T13:26:39.670694Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import paddle.nn.functional as F\n",
    "def train(model,train_loader):\n",
    "    global_step = 0\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        for step, batch in enumerate(train_loader, start=1):\n",
    "            input_ids, segment_ids, labels = batch\n",
    "            logits = model(input_ids, segment_ids)\n",
    "            loss = criterion(logits, labels)\n",
    "            probs = F.softmax(logits, axis=1)\n",
    "            correct = metric.compute(probs, labels)\n",
    "            metric.update(correct)\n",
    "            acc = metric.accumulate()\n",
    "            global_step += 1\n",
    "            \n",
    "            if global_step % 100 == 0 :\n",
    "                print(\"global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f\" % (global_step, epoch, step, loss, acc))\n",
    "            # 反向梯度回传，更新参数\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "    model.save_pretrained('/home/aistudio/checkpoint')\n",
    "    tokenizer.save_pretrained('/home/aistudio/checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T13:26:39.676922Z",
     "iopub.status.busy": "2022-10-28T13:26:39.676563Z",
     "iopub.status.idle": "2022-10-28T14:58:16.467306Z",
     "shell.execute_reply": "2022-10-28T14:58:16.466445Z",
     "shell.execute_reply.started": "2022-10-28T13:26:39.676901Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 100, epoch: 1, batch: 100, loss: 2.77928, acc: 0.12172\n",
      "global step 200, epoch: 1, batch: 200, loss: 2.64408, acc: 0.13984\n",
      "global step 300, epoch: 1, batch: 300, loss: 2.55930, acc: 0.15604\n",
      "global step 400, epoch: 1, batch: 400, loss: 2.44030, acc: 0.16516\n",
      "global step 500, epoch: 1, batch: 500, loss: 1.98619, acc: 0.17894\n",
      "global step 600, epoch: 1, batch: 600, loss: 2.37713, acc: 0.19534\n",
      "global step 700, epoch: 1, batch: 700, loss: 2.14108, acc: 0.20933\n",
      "global step 800, epoch: 2, batch: 18, loss: 2.23828, acc: 0.22083\n",
      "global step 900, epoch: 2, batch: 118, loss: 1.93426, acc: 0.23010\n",
      "global step 1000, epoch: 2, batch: 218, loss: 2.13473, acc: 0.23715\n",
      "global step 1100, epoch: 2, batch: 318, loss: 1.99726, acc: 0.24468\n",
      "global step 1200, epoch: 2, batch: 418, loss: 2.17148, acc: 0.25133\n",
      "global step 1300, epoch: 2, batch: 518, loss: 2.10856, acc: 0.25661\n",
      "global step 1400, epoch: 2, batch: 618, loss: 1.66179, acc: 0.26109\n",
      "global step 1500, epoch: 2, batch: 718, loss: 2.11861, acc: 0.26582\n",
      "global step 1600, epoch: 3, batch: 36, loss: 1.86102, acc: 0.27026\n",
      "global step 1700, epoch: 3, batch: 136, loss: 1.62041, acc: 0.27456\n",
      "global step 1800, epoch: 3, batch: 236, loss: 1.88043, acc: 0.27837\n",
      "global step 1900, epoch: 3, batch: 336, loss: 1.72398, acc: 0.28199\n",
      "global step 2000, epoch: 3, batch: 436, loss: 1.66869, acc: 0.28590\n",
      "global step 2100, epoch: 3, batch: 536, loss: 2.10876, acc: 0.28933\n",
      "global step 2200, epoch: 3, batch: 636, loss: 1.87913, acc: 0.29226\n",
      "global step 2300, epoch: 3, batch: 736, loss: 1.89427, acc: 0.29474\n",
      "global step 2400, epoch: 4, batch: 54, loss: 1.59386, acc: 0.29818\n",
      "global step 2500, epoch: 4, batch: 154, loss: 1.72248, acc: 0.30104\n",
      "global step 2600, epoch: 4, batch: 254, loss: 1.74181, acc: 0.30387\n",
      "global step 2700, epoch: 4, batch: 354, loss: 1.82141, acc: 0.30591\n",
      "global step 2800, epoch: 4, batch: 454, loss: 1.57618, acc: 0.30802\n",
      "global step 2900, epoch: 4, batch: 554, loss: 1.76275, acc: 0.31041\n",
      "global step 3000, epoch: 4, batch: 654, loss: 1.73563, acc: 0.31255\n",
      "global step 3100, epoch: 4, batch: 754, loss: 1.65590, acc: 0.31466\n",
      "global step 3200, epoch: 5, batch: 72, loss: 1.77273, acc: 0.31680\n",
      "global step 3300, epoch: 5, batch: 172, loss: 1.72609, acc: 0.31909\n",
      "global step 3400, epoch: 5, batch: 272, loss: 1.94948, acc: 0.32121\n",
      "global step 3500, epoch: 5, batch: 372, loss: 1.95090, acc: 0.32350\n",
      "global step 3600, epoch: 5, batch: 472, loss: 1.61202, acc: 0.32568\n",
      "global step 3700, epoch: 5, batch: 572, loss: 1.57071, acc: 0.32761\n",
      "global step 3800, epoch: 5, batch: 672, loss: 1.59247, acc: 0.32926\n",
      "global step 3900, epoch: 5, batch: 772, loss: 1.85763, acc: 0.33074\n",
      "global step 4000, epoch: 6, batch: 90, loss: 1.60694, acc: 0.33263\n",
      "global step 4100, epoch: 6, batch: 190, loss: 1.58528, acc: 0.33471\n",
      "global step 4200, epoch: 6, batch: 290, loss: 1.50107, acc: 0.33627\n",
      "global step 4300, epoch: 6, batch: 390, loss: 1.67479, acc: 0.33804\n",
      "global step 4400, epoch: 6, batch: 490, loss: 1.52089, acc: 0.33970\n",
      "global step 4500, epoch: 6, batch: 590, loss: 1.70213, acc: 0.34110\n",
      "global step 4600, epoch: 6, batch: 690, loss: 1.43340, acc: 0.34287\n",
      "global step 4700, epoch: 7, batch: 8, loss: 1.75362, acc: 0.34440\n",
      "global step 4800, epoch: 7, batch: 108, loss: 1.65386, acc: 0.34618\n",
      "global step 4900, epoch: 7, batch: 208, loss: 1.39543, acc: 0.34815\n",
      "global step 5000, epoch: 7, batch: 308, loss: 1.76099, acc: 0.34976\n",
      "global step 5100, epoch: 7, batch: 408, loss: 1.60886, acc: 0.35142\n",
      "global step 5200, epoch: 7, batch: 508, loss: 1.63619, acc: 0.35282\n",
      "global step 5300, epoch: 7, batch: 608, loss: 1.65181, acc: 0.35421\n",
      "global step 5400, epoch: 7, batch: 708, loss: 1.74656, acc: 0.35554\n",
      "global step 5500, epoch: 8, batch: 26, loss: 1.42535, acc: 0.35693\n",
      "global step 5600, epoch: 8, batch: 126, loss: 1.85901, acc: 0.35862\n",
      "global step 5700, epoch: 8, batch: 226, loss: 1.54223, acc: 0.36018\n",
      "global step 5800, epoch: 8, batch: 326, loss: 1.55621, acc: 0.36160\n",
      "global step 5900, epoch: 8, batch: 426, loss: 1.49772, acc: 0.36303\n",
      "global step 6000, epoch: 8, batch: 526, loss: 1.82393, acc: 0.36441\n",
      "global step 6100, epoch: 8, batch: 626, loss: 1.62882, acc: 0.36561\n",
      "global step 6200, epoch: 8, batch: 726, loss: 1.71293, acc: 0.36686\n",
      "global step 6300, epoch: 9, batch: 44, loss: 1.55596, acc: 0.36821\n",
      "global step 6400, epoch: 9, batch: 144, loss: 1.33793, acc: 0.36976\n",
      "global step 6500, epoch: 9, batch: 244, loss: 1.47819, acc: 0.37122\n",
      "global step 6600, epoch: 9, batch: 344, loss: 1.51488, acc: 0.37261\n",
      "global step 6700, epoch: 9, batch: 444, loss: 1.44378, acc: 0.37400\n",
      "global step 6800, epoch: 9, batch: 544, loss: 1.36122, acc: 0.37513\n",
      "global step 6900, epoch: 9, batch: 644, loss: 1.44364, acc: 0.37625\n",
      "global step 7000, epoch: 9, batch: 744, loss: 1.39654, acc: 0.37732\n",
      "global step 7100, epoch: 10, batch: 62, loss: 1.29118, acc: 0.37885\n",
      "global step 7200, epoch: 10, batch: 162, loss: 1.67643, acc: 0.38028\n",
      "global step 7300, epoch: 10, batch: 262, loss: 1.53982, acc: 0.38168\n",
      "global step 7400, epoch: 10, batch: 362, loss: 1.57444, acc: 0.38302\n",
      "global step 7500, epoch: 10, batch: 462, loss: 1.42646, acc: 0.38424\n",
      "global step 7600, epoch: 10, batch: 562, loss: 1.58474, acc: 0.38554\n",
      "global step 7700, epoch: 10, batch: 662, loss: 1.40779, acc: 0.38668\n",
      "global step 7800, epoch: 10, batch: 762, loss: 1.47414, acc: 0.38772\n",
      "global step 7900, epoch: 11, batch: 80, loss: 1.32799, acc: 0.38912\n",
      "global step 8000, epoch: 11, batch: 180, loss: 1.74661, acc: 0.39053\n",
      "global step 8100, epoch: 11, batch: 280, loss: 1.36953, acc: 0.39189\n",
      "global step 8200, epoch: 11, batch: 380, loss: 1.30436, acc: 0.39312\n",
      "global step 8300, epoch: 11, batch: 480, loss: 1.80412, acc: 0.39431\n",
      "global step 8400, epoch: 11, batch: 580, loss: 1.45797, acc: 0.39545\n",
      "global step 8500, epoch: 11, batch: 680, loss: 1.39294, acc: 0.39655\n",
      "global step 8600, epoch: 11, batch: 780, loss: 1.39037, acc: 0.39753\n",
      "global step 8700, epoch: 12, batch: 98, loss: 1.43053, acc: 0.39900\n",
      "global step 8800, epoch: 12, batch: 198, loss: 1.09436, acc: 0.40056\n",
      "global step 8900, epoch: 12, batch: 298, loss: 1.52115, acc: 0.40170\n",
      "global step 9000, epoch: 12, batch: 398, loss: 1.36903, acc: 0.40296\n",
      "global step 9100, epoch: 12, batch: 498, loss: 1.24937, acc: 0.40429\n",
      "global step 9200, epoch: 12, batch: 598, loss: 1.39816, acc: 0.40549\n",
      "global step 9300, epoch: 12, batch: 698, loss: 1.33193, acc: 0.40657\n",
      "global step 9400, epoch: 13, batch: 16, loss: 1.17903, acc: 0.40768\n",
      "global step 9500, epoch: 13, batch: 116, loss: 0.90998, acc: 0.40917\n",
      "global step 9600, epoch: 13, batch: 216, loss: 1.29919, acc: 0.41038\n",
      "global step 9700, epoch: 13, batch: 316, loss: 1.39278, acc: 0.41173\n",
      "global step 9800, epoch: 13, batch: 416, loss: 1.27304, acc: 0.41295\n",
      "global step 9900, epoch: 13, batch: 516, loss: 1.27702, acc: 0.41410\n",
      "global step 10000, epoch: 13, batch: 616, loss: 1.21399, acc: 0.41539\n",
      "global step 10100, epoch: 13, batch: 716, loss: 1.20914, acc: 0.41643\n",
      "global step 10200, epoch: 14, batch: 34, loss: 1.17891, acc: 0.41778\n",
      "global step 10300, epoch: 14, batch: 134, loss: 1.28289, acc: 0.41926\n",
      "global step 10400, epoch: 14, batch: 234, loss: 1.02210, acc: 0.42068\n",
      "global step 10500, epoch: 14, batch: 334, loss: 1.09644, acc: 0.42198\n",
      "global step 10600, epoch: 14, batch: 434, loss: 1.46489, acc: 0.42326\n",
      "global step 10700, epoch: 14, batch: 534, loss: 1.22573, acc: 0.42448\n",
      "global step 10800, epoch: 14, batch: 634, loss: 1.36278, acc: 0.42569\n",
      "global step 10900, epoch: 14, batch: 734, loss: 1.37208, acc: 0.42685\n",
      "global step 11000, epoch: 15, batch: 52, loss: 1.19450, acc: 0.42817\n",
      "global step 11100, epoch: 15, batch: 152, loss: 0.89136, acc: 0.42963\n",
      "global step 11200, epoch: 15, batch: 252, loss: 1.20794, acc: 0.43098\n",
      "global step 11300, epoch: 15, batch: 352, loss: 1.15054, acc: 0.43234\n",
      "global step 11400, epoch: 15, batch: 452, loss: 1.31641, acc: 0.43355\n",
      "global step 11500, epoch: 15, batch: 552, loss: 1.32727, acc: 0.43482\n",
      "global step 11600, epoch: 15, batch: 652, loss: 1.32985, acc: 0.43601\n",
      "global step 11700, epoch: 15, batch: 752, loss: 0.99479, acc: 0.43716\n",
      "global step 11800, epoch: 16, batch: 70, loss: 0.94652, acc: 0.43855\n",
      "global step 11900, epoch: 16, batch: 170, loss: 1.23223, acc: 0.43997\n",
      "global step 12000, epoch: 16, batch: 270, loss: 1.17989, acc: 0.44129\n",
      "global step 12100, epoch: 16, batch: 370, loss: 1.02283, acc: 0.44266\n",
      "global step 12200, epoch: 16, batch: 470, loss: 1.17339, acc: 0.44396\n",
      "global step 12300, epoch: 16, batch: 570, loss: 1.18830, acc: 0.44522\n",
      "global step 12400, epoch: 16, batch: 670, loss: 1.11484, acc: 0.44645\n",
      "global step 12500, epoch: 16, batch: 770, loss: 1.19301, acc: 0.44765\n",
      "global step 12600, epoch: 17, batch: 88, loss: 0.94149, acc: 0.44917\n",
      "global step 12700, epoch: 17, batch: 188, loss: 1.03589, acc: 0.45054\n",
      "global step 12800, epoch: 17, batch: 288, loss: 0.88407, acc: 0.45195\n",
      "global step 12900, epoch: 17, batch: 388, loss: 1.00258, acc: 0.45324\n",
      "global step 13000, epoch: 17, batch: 488, loss: 0.95842, acc: 0.45454\n",
      "global step 13100, epoch: 17, batch: 588, loss: 1.10467, acc: 0.45577\n",
      "global step 13200, epoch: 17, batch: 688, loss: 0.89311, acc: 0.45708\n",
      "global step 13300, epoch: 18, batch: 6, loss: 0.90296, acc: 0.45830\n",
      "global step 13400, epoch: 18, batch: 106, loss: 1.02789, acc: 0.45984\n",
      "global step 13500, epoch: 18, batch: 206, loss: 1.21752, acc: 0.46130\n",
      "global step 13600, epoch: 18, batch: 306, loss: 0.83824, acc: 0.46278\n",
      "global step 13700, epoch: 18, batch: 406, loss: 0.84612, acc: 0.46412\n",
      "global step 13800, epoch: 18, batch: 506, loss: 0.87321, acc: 0.46549\n",
      "global step 13900, epoch: 18, batch: 606, loss: 1.01809, acc: 0.46676\n",
      "global step 14000, epoch: 18, batch: 706, loss: 0.85561, acc: 0.46802\n",
      "global step 14100, epoch: 19, batch: 24, loss: 0.98522, acc: 0.46930\n",
      "global step 14200, epoch: 19, batch: 124, loss: 0.86907, acc: 0.47082\n",
      "global step 14300, epoch: 19, batch: 224, loss: 1.10450, acc: 0.47221\n",
      "global step 14400, epoch: 19, batch: 324, loss: 0.93677, acc: 0.47361\n",
      "global step 14500, epoch: 19, batch: 424, loss: 0.95682, acc: 0.47502\n",
      "global step 14600, epoch: 19, batch: 524, loss: 1.01283, acc: 0.47640\n",
      "global step 14700, epoch: 19, batch: 624, loss: 0.85983, acc: 0.47772\n",
      "global step 14800, epoch: 19, batch: 724, loss: 0.87492, acc: 0.47897\n",
      "global step 14900, epoch: 20, batch: 42, loss: 0.76814, acc: 0.48045\n",
      "global step 15000, epoch: 20, batch: 142, loss: 0.91232, acc: 0.48196\n",
      "global step 15100, epoch: 20, batch: 242, loss: 0.59594, acc: 0.48344\n",
      "global step 15200, epoch: 20, batch: 342, loss: 0.66366, acc: 0.48480\n",
      "global step 15300, epoch: 20, batch: 442, loss: 0.68450, acc: 0.48611\n",
      "global step 15400, epoch: 20, batch: 542, loss: 0.81874, acc: 0.48753\n",
      "global step 15500, epoch: 20, batch: 642, loss: 0.78945, acc: 0.48876\n",
      "global step 15600, epoch: 20, batch: 742, loss: 0.84630, acc: 0.49000\n"
     ]
    }
   ],
   "source": [
    "train(model,train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 模型预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T14:58:16.469125Z",
     "iopub.status.busy": "2022-10-28T14:58:16.468707Z",
     "iopub.status.idle": "2022-10-28T14:58:18.902995Z",
     "shell.execute_reply": "2022-10-28T14:58:18.902347Z",
     "shell.execute_reply.started": "2022-10-28T14:58:16.469098Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-10-28 22:58:16,470] [    INFO] - Already cached /home/aistudio/.paddlenlp/models/ernie-1.0/ernie_v1_chn_base.pdparams\n"
     ]
    }
   ],
   "source": [
    "model = ppnlp.transformers.ErnieForSequenceClassification.from_pretrained('ernie-1.0', num_classes=32)\n",
    "model_dict = paddle.load('/home/aistudio/checkpoint/model_state.pdparams')\n",
    "model.set_dict(model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 在测试集上预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T14:58:18.904214Z",
     "iopub.status.busy": "2022-10-28T14:58:18.903861Z",
     "iopub.status.idle": "2022-10-28T14:58:18.906968Z",
     "shell.execute_reply": "2022-10-28T14:58:18.906447Z",
     "shell.execute_reply.started": "2022-10-28T14:58:18.904192Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label_map = dict(zip(label_idx.values(),label_idx.keys()))\n",
    "# model.eval()\n",
    "# predictions = []\n",
    "# for input_ids, segment_ids in test_loader:\n",
    "#     logits = model(input_ids, segment_ids)\n",
    "#     probs = F.softmax(logits, axis=1)  \n",
    "#     idx = paddle.argmax(probs, axis=1).numpy()\n",
    "#     idx = idx.tolist()\n",
    "#     labels = [label_map[i] for i in idx]\n",
    "#     predictions.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T14:58:18.908056Z",
     "iopub.status.busy": "2022-10-28T14:58:18.907685Z",
     "iopub.status.idle": "2022-10-28T14:58:18.910501Z",
     "shell.execute_reply": "2022-10-28T14:58:18.910020Z",
     "shell.execute_reply.started": "2022-10-28T14:58:18.908035Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# predictions[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T14:58:18.911555Z",
     "iopub.status.busy": "2022-10-28T14:58:18.911198Z",
     "iopub.status.idle": "2022-10-28T15:00:16.052481Z",
     "shell.execute_reply": "2022-10-28T15:00:16.051636Z",
     "shell.execute_reply.started": "2022-10-28T14:58:18.911535Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pre_read(data_path):\n",
    "    data = pd.read_csv(data_path,encoding=\"utf-8\")\n",
    "    for index,row in data.iterrows():\n",
    "        sentence = row[1]\n",
    "        yield {'text': sentence}\n",
    "\n",
    "pre_func = partial(\n",
    "    convert_example,\n",
    "    tokenizer = tokenizer,    \n",
    "    max_seq_length = max_seq_length,\n",
    "    is_test = True)\n",
    "\n",
    "\n",
    "pre_loader = load_dataset(pre_read, data_path=\"./work/BDCI/testA.csv\",lazy=False) \n",
    "pre_ds = pre_loader.map(pre_func)       \n",
    "pre_loader = paddle.io.DataLoader(\n",
    "        dataset=pre_ds,\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        collate_fn=batchify_fn_test,\n",
    "        return_list=True)\n",
    "model.eval()\n",
    "predictions = []\n",
    "for input_ids, segment_ids in pre_loader:\n",
    "    logits = model(input_ids, segment_ids)\n",
    "    probs = F.softmax(logits, axis=1)  \n",
    "    idx = paddle.argmax(probs, axis=1).numpy()\n",
    "    idx = idx.tolist()\n",
    "    labels = [i for i in idx]\n",
    "    predictions.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-28T15:03:50.295836Z",
     "iopub.status.busy": "2022-10-28T15:03:50.295392Z",
     "iopub.status.idle": "2022-10-28T15:03:50.849109Z",
     "shell.execute_reply": "2022-10-28T15:03:50.848489Z",
     "shell.execute_reply.started": "2022-10-28T15:03:50.295809Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./work/BDCI/testA.csv\",encoding=\"utf-8\")\n",
    "df = pd.DataFrame(data={\"id\":data[\"id\"],\"label\":predictions})\n",
    "df.to_csv(\"submisstion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
